{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libratries\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# function: create_onehot_classifier(y)\n",
    "#   Creates a one hot encoded array between (0,9) \n",
    "#\n",
    "# input: mx1 array of intergers between (0,9), \n",
    "#        where m represents the number of training examples\n",
    "#\n",
    "# output: mx10 array of one's hot encoded values\n",
    "############################################################\n",
    "\n",
    "\n",
    "def create_onehot_classifier(y):\n",
    "    \n",
    "    #Create and array zeros array in the shape of the final output\n",
    "    arr_train = np.zeros((y.shape[0],10),dtype=int) \n",
    "    \n",
    "    i=0 # Inititalize the index\n",
    "    \n",
    "    # Interate through each example and write that example to \n",
    "    #   the zeros array generated earlier \n",
    "    for val in y:\n",
    "        temp_arr = np.zeros(10)\n",
    "        temp_arr[0] = 1\n",
    "        temp_arr = np.roll(temp_arr, val)\n",
    "        arr_train[i,:] = temp_arr\n",
    "        i=i+1\n",
    "    return arr_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  60000\n",
      "Number of test examples:  10000\n",
      "x_train shape:  (60000, 28, 28)\n",
      "y_train shape:  (60000,)\n",
      "x_test shape:  (10000, 28, 28)\n",
      "y_test shape:  (10000,)\n",
      "\n",
      "Formatted x_train shape: (60000, 784)\n",
      "Formatted y_train shape: (60000, 10)\n",
      "Formatted x_test shape: (10000, 784)\n",
      "Formatted y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# This block loads the data, and places it in the\n",
    "#    correct format for training\n",
    "\n",
    "#Load mnist data\n",
    "\n",
    "(x_train_read,y_train_read), (x_test_read,y_test_read) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Print the shape of data of orginial data\n",
    "print(\"Number of training examples: \", x_train_read.shape[0])\n",
    "print(\"Number of test examples: \", x_test_read.shape[0])\n",
    "print(\"x_train shape: \", x_train_read.shape)\n",
    "print(\"y_train shape: \", y_train_read.shape)\n",
    "print(\"x_test shape: \", x_test_read.shape)\n",
    "print(\"y_test shape: \", y_test_read.shape)\n",
    "\n",
    "\n",
    "# Unwrape the data the data into a single column for each example\n",
    "x_train = x_train_read.reshape(x_train_read.shape[0],-1)\n",
    "x_test = x_test_read.reshape(x_test_read.shape[0],-1)\n",
    "\n",
    "y_train = create_onehot_classifier(y_train_read)\n",
    "y_test = create_onehot_classifier(y_test_read)\n",
    "\n",
    "print(\"\\nFormatted x_train shape:\",x_train.shape)\n",
    "print(\"Formatted y_train shape:\",y_train.shape)\n",
    "print(\"Formatted x_test shape:\",x_test.shape)\n",
    "print(\"Formatted y_test shape:\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The foundation of any AI application is the data provided to the algorithm.  The cell below will load a random sample of the data.\n",
    "\n",
    "Rerun the cell multiple times to get familiar with the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:  6\n",
      "y_train[51378] = [0 0 0 0 0 0 1 0 0 0]\n",
      "x_train[51378]:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore the Data\n",
    "# Rerun this cell to load additonal examples\n",
    "\n",
    "# Integer between 0-59,999\n",
    "index = np.random.randint(0,59999)\n",
    "plt.imshow(x_train_read[index], cmap='gray')\n",
    "str_yout = 'y_train['+str(index)+'] ='\n",
    "str_xout = 'x_train['+str(index)+']:'\n",
    "print(\"Number: \", y_train_read[index])\n",
    "print(str_yout,y_train[index])\n",
    "print(str_xout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block contains the function to generate the model\n",
    "## EDIT VALUES IN THIS BLOCK TO CHANGE PERFORMANCE ##\n",
    "\n",
    "def create_model():\n",
    "   \n",
    "    # Hyper Parameters\n",
    "    #### EDIT THESE VALUES TO CHANGE PERFOMANCE  #####\n",
    "    learning_rate = 0.0006 # Learning is highly depdendent on this values\n",
    "    hidden_layer1_size = 8 # number of neurons in hidden layer 1\n",
    "    hidden_layer2_size = 4 # number of neurons in hidden layer 2\n",
    "    #hidden_layer3_size = 2\n",
    "    \n",
    "    # Block defining neural network \n",
    "    ####  EDIT NUMBER OF LAYERS/NEURONS TO ChANGE PERFORMANCE ###\n",
    "    \n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        # Define Input Layer/Hidden Layer 1\n",
    "        keras.layers.Dense(hidden_layer1_size, activation=tf.nn.relu, input_shape = (784,)),\n",
    "        # Define Hidden Layer 2\n",
    "        keras.layers.Dense(hidden_layer2_size, activation=tf.nn.relu),\n",
    "        # Additional Hidden Layers here:\n",
    "        #keras.layers.Dense(hidden_layer3_size, activation=tf.nn.relu),\n",
    "        # Define Output layer\n",
    "        keras.layers.Dense(10, activation=tf.keras.activations.softmax)\n",
    "    ])\n",
    "\n",
    "    # By default will use:\n",
    "    #   Adams Optimizer with learning rate 0.0005\n",
    "    #       Adams is an algorithm used to update weights/biases during training\n",
    "    #       There are other optimezers available\n",
    "    #   Mean Square Error Loss Function\n",
    "    #   Metrics, which is only provided for information and not used \n",
    "    #      for training.  In this example a accuracy is choosen. \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "                  loss=tf.keras.losses.mean_squared_error,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load the neural network \n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.1021 - accuracy: 0.2637\n",
      "Epoch 2/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0610 - accuracy: 0.4538\n",
      "Epoch 3/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0579 - accuracy: 0.4886\n",
      "Epoch 4/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0538 - accuracy: 0.5462\n",
      "Epoch 5/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0479 - accuracy: 0.6194\n",
      "Epoch 6/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0456 - accuracy: 0.6442\n",
      "Epoch 7/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0432 - accuracy: 0.6627\n",
      "Epoch 8/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0415 - accuracy: 0.6894\n",
      "Epoch 9/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0398 - accuracy: 0.7137\n",
      "Epoch 10/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0384 - accuracy: 0.7343\n",
      "Epoch 11/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.7436\n",
      "Epoch 12/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0358 - accuracy: 0.7530\n",
      "Epoch 13/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0306 - accuracy: 0.8066\n",
      "Epoch 14/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0269 - accuracy: 0.8443\n",
      "Epoch 15/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0263 - accuracy: 0.8478\n",
      "Epoch 16/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0248 - accuracy: 0.8558\n",
      "Epoch 17/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0245 - accuracy: 0.8577\n",
      "Epoch 18/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0240 - accuracy: 0.8623\n",
      "Epoch 19/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0234 - accuracy: 0.8660\n",
      "Epoch 20/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.8680\n",
      "Epoch 21/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0220 - accuracy: 0.8747\n",
      "Epoch 22/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0218 - accuracy: 0.8739\n",
      "Epoch 23/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.8785\n",
      "Epoch 24/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0206 - accuracy: 0.8824\n",
      "Epoch 25/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0205 - accuracy: 0.8834\n",
      "Epoch 26/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0207 - accuracy: 0.8803\n",
      "Epoch 27/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0195 - accuracy: 0.8882\n",
      "Epoch 28/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0198 - accuracy: 0.8868\n",
      "Epoch 29/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0189 - accuracy: 0.8926\n",
      "Epoch 30/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0195 - accuracy: 0.8882\n",
      "Epoch 31/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0192 - accuracy: 0.8897\n",
      "Epoch 32/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0186 - accuracy: 0.8939\n",
      "Epoch 33/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0190 - accuracy: 0.8908\n",
      "Epoch 34/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0180 - accuracy: 0.8971\n",
      "Epoch 35/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0178 - accuracy: 0.8993\n",
      "Epoch 36/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0184 - accuracy: 0.8950\n",
      "Epoch 37/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0178 - accuracy: 0.8988\n",
      "Epoch 38/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0177 - accuracy: 0.8997\n",
      "Epoch 39/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0176 - accuracy: 0.9007\n",
      "Epoch 40/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0174 - accuracy: 0.9017\n",
      "Epoch 41/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0176 - accuracy: 0.8985\n",
      "Epoch 42/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0170 - accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0175 - accuracy: 0.9008\n",
      "Epoch 44/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0173 - accuracy: 0.9011\n",
      "Epoch 45/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0167 - accuracy: 0.9050\n",
      "Epoch 46/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0166 - accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0168 - accuracy: 0.9048\n",
      "Epoch 48/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0168 - accuracy: 0.9040\n",
      "Epoch 49/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0166 - accuracy: 0.9056\n",
      "Epoch 50/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0167 - accuracy: 0.9050\n",
      "Epoch 51/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0167 - accuracy: 0.9037\n",
      "Epoch 52/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0162 - accuracy: 0.9073\n",
      "Epoch 53/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0162 - accuracy: 0.9075\n",
      "Epoch 54/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0157 - accuracy: 0.9111\n",
      "Epoch 55/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0154 - accuracy: 0.9118\n",
      "Epoch 56/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0158 - accuracy: 0.9088\n",
      "Epoch 57/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0154 - accuracy: 0.9127\n",
      "Epoch 58/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0164 - accuracy: 0.9061\n",
      "Epoch 59/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0155 - accuracy: 0.9113\n",
      "Epoch 60/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0157 - accuracy: 0.9104\n",
      "Epoch 61/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0158 - accuracy: 0.9108\n",
      "Epoch 62/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0155 - accuracy: 0.9118\n",
      "Epoch 63/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0155 - accuracy: 0.9113\n",
      "Epoch 64/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0158 - accuracy: 0.9106\n",
      "Epoch 65/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0150 - accuracy: 0.9148\n",
      "Epoch 66/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0156 - accuracy: 0.9120\n",
      "Epoch 67/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9142\n",
      "Epoch 68/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9171\n",
      "Epoch 69/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0151 - accuracy: 0.9146\n",
      "Epoch 70/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0147 - accuracy: 0.9162\n",
      "Epoch 71/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9145\n",
      "Epoch 72/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9144\n",
      "Epoch 73/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0154 - accuracy: 0.9126\n",
      "Epoch 74/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0144 - accuracy: 0.9191\n",
      "Epoch 75/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9142\n",
      "Epoch 76/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0152 - accuracy: 0.9142\n",
      "Epoch 77/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9171\n",
      "Epoch 78/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9166\n",
      "Epoch 79/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0154 - accuracy: 0.9123\n",
      "Epoch 80/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0147 - accuracy: 0.9160\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0149 - accuracy: 0.9154\n",
      "Epoch 82/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0147 - accuracy: 0.9161\n",
      "Epoch 83/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0148 - accuracy: 0.9160\n",
      "Epoch 84/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9169\n",
      "Epoch 85/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0147 - accuracy: 0.9168\n",
      "Epoch 86/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0152 - accuracy: 0.9135\n",
      "Epoch 87/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0147 - accuracy: 0.9169\n",
      "Epoch 88/100\n",
      "938/938 [==============================] - 1s 2ms/step - loss: 0.0144 - accuracy: 0.9182\n",
      "Epoch 89/100\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.0147 - accuracy: 0.9166\n",
      "Epoch 90/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0146 - accuracy: 0.9170\n",
      "Epoch 91/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9179\n",
      "Epoch 92/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0147 - accuracy: 0.9174\n",
      "Epoch 93/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9176\n",
      "Epoch 94/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0143 - accuracy: 0.9185\n",
      "Epoch 95/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0147 - accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0148 - accuracy: 0.9158\n",
      "Epoch 97/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9180\n",
      "Epoch 98/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9208\n",
      "Epoch 99/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9185: 0s - loss: 0.0145 \n",
      "Epoch 100/100\n",
      "938/938 [==============================] - 1s 1ms/step - loss: 0.0139 - accuracy: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f918504d790>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model using the .fit method\n",
    "# EDIT Epochs, batch_size, inital_epoch\n",
    "epoch_num = 100\n",
    "epoch_init = 0\n",
    "model.fit(x_train, y_train, epochs = epoch_num, batch_size = 64,initial_epoch=epoch_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy =  0.909600019454956\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test,verbose = 'False')\n",
    "print(\"Test Accuracy = \",  test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:            7\n",
      "Model Prediction:  7\n",
      "x_train[51378]:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let Look at how the model perfromed\n",
    "# Rerun the model to figure which test cases your model\n",
    "#    predicted right and which ones it predicted wrong\n",
    "# \n",
    "# Evaluating which data your model does well on which ones\n",
    "#   need improvemt can focus your data collection and traing efforts \n",
    "\n",
    "index = np.random.randint(0,x_train.shape[0])\n",
    "plt.imshow(x_train_read[index], cmap='gray')\n",
    "\n",
    "xin = x_train[index].reshape(-1,1)\n",
    "xin = xin.T\n",
    "arr_predict = model.predict(xin,verbose = 'False')\n",
    "# transform array to number\n",
    "result = np.argmax(arr_predict)\n",
    "\n",
    "print(\"Number:           \", y_train_read[index])\n",
    "print(\"Model Prediction: \", result)\n",
    "print(str_xout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to save your model\n",
    "# This file will be the submission to the programming challenge\n",
    "### EDIT NAME ###\n",
    "model.save('ESP32_Num_mnist_8_4.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a TensorFlow Lite Mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the model to the TensorFlow Lite format with quantization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
